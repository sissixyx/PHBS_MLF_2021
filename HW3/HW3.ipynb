{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #3: PCA/Hyperparameter/CV\n",
    "Data source: http://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('4year.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bankruptcy'] = (df['class']==b'1')\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "df.columns = ['X{0:02d}'.format(k) for k in range(1,65)] + ['bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9773.000000</td>\n",
       "      <td>9792.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.792000e+03</td>\n",
       "      <td>9771.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9776.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9178.000000</td>\n",
       "      <td>9760.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.596404</td>\n",
       "      <td>0.130959</td>\n",
       "      <td>8.136600</td>\n",
       "      <td>6.465164e+01</td>\n",
       "      <td>-0.059273</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>19.884016</td>\n",
       "      <td>1.882296</td>\n",
       "      <td>0.389040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.686330e+03</td>\n",
       "      <td>-0.992263</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1.133287</td>\n",
       "      <td>0.856053</td>\n",
       "      <td>118.156064</td>\n",
       "      <td>25.194430</td>\n",
       "      <td>2.015157e+03</td>\n",
       "      <td>8.660813</td>\n",
       "      <td>35.949619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.359321</td>\n",
       "      <td>4.587122</td>\n",
       "      <td>4.559074</td>\n",
       "      <td>290.647281</td>\n",
       "      <td>1.475939e+04</td>\n",
       "      <td>6.812754</td>\n",
       "      <td>0.533344</td>\n",
       "      <td>698.697015</td>\n",
       "      <td>17.674650</td>\n",
       "      <td>4.590299</td>\n",
       "      <td>...</td>\n",
       "      <td>7.605261e+04</td>\n",
       "      <td>77.007971</td>\n",
       "      <td>8.945365</td>\n",
       "      <td>8.038201</td>\n",
       "      <td>26.393305</td>\n",
       "      <td>3230.316692</td>\n",
       "      <td>1099.260821</td>\n",
       "      <td>1.171461e+05</td>\n",
       "      <td>60.838202</td>\n",
       "      <td>483.318623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.458000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>-0.045319</td>\n",
       "      <td>-3.794600e+05</td>\n",
       "      <td>-486.820000</td>\n",
       "      <td>-12.458000</td>\n",
       "      <td>-1.848200</td>\n",
       "      <td>-0.032371</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.132200e+05</td>\n",
       "      <td>-7522.100000</td>\n",
       "      <td>-597.420000</td>\n",
       "      <td>-30.892000</td>\n",
       "      <td>-284.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.656000</td>\n",
       "      <td>-1.496500e+04</td>\n",
       "      <td>-0.024390</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>-5.121700e+01</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>1.006675</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184000e+01</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.885722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.356325</td>\n",
       "      <td>4.267700</td>\n",
       "      <td>4.323400e+01</td>\n",
       "      <td>2.938800</td>\n",
       "      <td>2.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.467740</td>\n",
       "      <td>0.199290</td>\n",
       "      <td>1.591800</td>\n",
       "      <td>-5.557600e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>1.088700</td>\n",
       "      <td>1.161300</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>...</td>\n",
       "      <td>9.503300e+02</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.958305</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>9.482000</td>\n",
       "      <td>6.283550</td>\n",
       "      <td>7.472900e+01</td>\n",
       "      <td>4.848900</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.689255</td>\n",
       "      <td>0.410670</td>\n",
       "      <td>2.880400</td>\n",
       "      <td>5.573200e+01</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>2.691000</td>\n",
       "      <td>1.970225</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>...</td>\n",
       "      <td>4.694550e+03</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.996163</td>\n",
       "      <td>0.211790</td>\n",
       "      <td>19.506000</td>\n",
       "      <td>9.938200</td>\n",
       "      <td>1.233450e+02</td>\n",
       "      <td>8.363800</td>\n",
       "      <td>9.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.482000</td>\n",
       "      <td>446.910000</td>\n",
       "      <td>22.769000</td>\n",
       "      <td>27146.000000</td>\n",
       "      <td>1.034100e+06</td>\n",
       "      <td>322.200000</td>\n",
       "      <td>38.618000</td>\n",
       "      <td>53209.000000</td>\n",
       "      <td>1704.800000</td>\n",
       "      <td>12.602000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123700e+06</td>\n",
       "      <td>112.020000</td>\n",
       "      <td>226.760000</td>\n",
       "      <td>668.750000</td>\n",
       "      <td>1661.000000</td>\n",
       "      <td>251570.000000</td>\n",
       "      <td>108000.000000</td>\n",
       "      <td>1.077900e+07</td>\n",
       "      <td>5662.400000</td>\n",
       "      <td>21153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X01          X02          X03           X04           X05  \\\n",
       "count  9791.000000  9791.000000  9791.000000   9749.000000  9.771000e+03   \n",
       "mean      0.043019     0.596404     0.130959      8.136600  6.465164e+01   \n",
       "std       0.359321     4.587122     4.559074    290.647281  1.475939e+04   \n",
       "min     -12.458000     0.000000  -445.910000     -0.045319 -3.794600e+05   \n",
       "25%       0.001321     0.263145     0.020377      1.047000 -5.121700e+01   \n",
       "50%       0.041364     0.467740     0.199290      1.591800 -5.557600e-02   \n",
       "75%       0.111130     0.689255     0.410670      2.880400  5.573200e+01   \n",
       "max      20.482000   446.910000    22.769000  27146.000000  1.034100e+06   \n",
       "\n",
       "               X06          X07           X08          X09          X10  ...  \\\n",
       "count  9791.000000  9791.000000   9773.000000  9792.000000  9791.000000  ...   \n",
       "mean     -0.059273     0.059446     19.884016     1.882296     0.389040  ...   \n",
       "std       6.812754     0.533344    698.697015    17.674650     4.590299  ...   \n",
       "min    -486.820000   -12.458000     -1.848200    -0.032371  -445.910000  ...   \n",
       "25%      -0.000578     0.003004      0.428300     1.006675     0.294440  ...   \n",
       "50%       0.000000     0.048820      1.088700     1.161300     0.510450  ...   \n",
       "75%       0.065322     0.126940      2.691000     1.970225     0.714290  ...   \n",
       "max     322.200000    38.618000  53209.000000  1704.800000    12.602000  ...   \n",
       "\n",
       "                X55          X56          X57          X58          X59  \\\n",
       "count  9.792000e+03  9771.000000  9791.000000  9776.000000  9791.000000   \n",
       "mean   7.686330e+03    -0.992263     0.035022     1.133287     0.856053   \n",
       "std    7.605261e+04    77.007971     8.945365     8.038201    26.393305   \n",
       "min   -7.132200e+05 -7522.100000  -597.420000   -30.892000  -284.380000   \n",
       "25%    2.184000e+01     0.003121     0.008768     0.885722     0.000000   \n",
       "50%    9.503300e+02     0.043679     0.098026     0.958305     0.002129   \n",
       "75%    4.694550e+03     0.117170     0.242680     0.996163     0.211790   \n",
       "max    6.123700e+06   112.020000   226.760000   668.750000  1661.000000   \n",
       "\n",
       "                 X60            X61           X62          X63           X64  \n",
       "count    9178.000000    9760.000000  9.771000e+03  9749.000000   9561.000000  \n",
       "mean      118.156064      25.194430  2.015157e+03     8.660813     35.949619  \n",
       "std      3230.316692    1099.260821  1.171461e+05    60.838202    483.318623  \n",
       "min         0.000000     -12.656000 -1.496500e+04    -0.024390     -0.000015  \n",
       "25%         5.356325       4.267700  4.323400e+01     2.938800      2.012900  \n",
       "50%         9.482000       6.283550  7.472900e+01     4.848900      4.041600  \n",
       "75%        19.506000       9.938200  1.233450e+02     8.363800      9.413500  \n",
       "max    251570.000000  108000.000000  1.077900e+07  5662.400000  21153.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>bankruptcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159290</td>\n",
       "      <td>0.46240</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>1.1683</td>\n",
       "      <td>-44.853</td>\n",
       "      <td>0.467020</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.82895</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>0.38330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.41557</td>\n",
       "      <td>0.89101</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>7.7928</td>\n",
       "      <td>4.9914</td>\n",
       "      <td>119.810</td>\n",
       "      <td>3.0465</td>\n",
       "      <td>3.0560</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.127430</td>\n",
       "      <td>0.46243</td>\n",
       "      <td>0.26917</td>\n",
       "      <td>1.7517</td>\n",
       "      <td>7.597</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>-0.127430</td>\n",
       "      <td>1.16250</td>\n",
       "      <td>1.2944</td>\n",
       "      <td>0.53757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089372</td>\n",
       "      <td>-0.23704</td>\n",
       "      <td>1.06250</td>\n",
       "      <td>0.150410</td>\n",
       "      <td>5.4327</td>\n",
       "      <td>3.4629</td>\n",
       "      <td>100.970</td>\n",
       "      <td>3.6150</td>\n",
       "      <td>3.4725</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070488</td>\n",
       "      <td>0.23570</td>\n",
       "      <td>0.52781</td>\n",
       "      <td>3.2393</td>\n",
       "      <td>125.680</td>\n",
       "      <td>0.163670</td>\n",
       "      <td>0.086895</td>\n",
       "      <td>2.87180</td>\n",
       "      <td>1.0574</td>\n",
       "      <td>0.67689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.10413</td>\n",
       "      <td>0.94571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.1070</td>\n",
       "      <td>3.3808</td>\n",
       "      <td>76.076</td>\n",
       "      <td>4.7978</td>\n",
       "      <td>4.7818</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136760</td>\n",
       "      <td>0.40538</td>\n",
       "      <td>0.31543</td>\n",
       "      <td>1.8705</td>\n",
       "      <td>19.115</td>\n",
       "      <td>0.504970</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>1.45390</td>\n",
       "      <td>1.1144</td>\n",
       "      <td>0.58938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.23203</td>\n",
       "      <td>0.89737</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>6.1384</td>\n",
       "      <td>4.2241</td>\n",
       "      <td>88.299</td>\n",
       "      <td>4.1337</td>\n",
       "      <td>4.6484</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.69793</td>\n",
       "      <td>0.18878</td>\n",
       "      <td>1.2713</td>\n",
       "      <td>-15.344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.43282</td>\n",
       "      <td>1.7350</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439880</td>\n",
       "      <td>-0.36440</td>\n",
       "      <td>0.57153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.8010</td>\n",
       "      <td>2.7925</td>\n",
       "      <td>146.390</td>\n",
       "      <td>2.4934</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X01      X02      X03     X04      X05       X06       X07      X08  \\\n",
       "0  0.159290  0.46240  0.07773  1.1683  -44.853  0.467020  0.189480  0.82895   \n",
       "1 -0.127430  0.46243  0.26917  1.7517    7.597  0.000925 -0.127430  1.16250   \n",
       "2  0.070488  0.23570  0.52781  3.2393  125.680  0.163670  0.086895  2.87180   \n",
       "3  0.136760  0.40538  0.31543  1.8705   19.115  0.504970  0.136760  1.45390   \n",
       "4 -0.110080  0.69793  0.18878  1.2713  -15.344  0.000000 -0.110080  0.43282   \n",
       "\n",
       "      X09      X10  ...       X56      X57      X58       X59      X60  \\\n",
       "0  1.1223  0.38330  ...  0.108990  0.41557  0.89101  0.001422   7.7928   \n",
       "1  1.2944  0.53757  ... -0.089372 -0.23704  1.06250  0.150410   5.4327   \n",
       "2  1.0574  0.67689  ...  0.054286  0.10413  0.94571  0.000000   7.1070   \n",
       "3  1.1144  0.58938  ...  0.102630  0.23203  0.89737  0.073024   6.1384   \n",
       "4  1.7350  0.30207  ...  0.439880 -0.36440  0.57153  0.000000  18.8010   \n",
       "\n",
       "      X61      X62     X63      X64  bankruptcy  \n",
       "0  4.9914  119.810  3.0465   3.0560       False  \n",
       "1  3.4629  100.970  3.6150   3.4725       False  \n",
       "2  3.3808   76.076  4.7978   4.7818       False  \n",
       "3  4.2241   88.299  4.1337   4.6484       False  \n",
       "4  2.7925  146.390  2.4934  15.0360       False  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.bankruptcy == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isna().sum()\n",
    "X_imp = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = X_imp[:, :-1], X_imp[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 64)\n",
      "(2938, 64)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as skpre\n",
    "\n",
    "stdsc = skpre.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "print(X_train_std.shape)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the 2 most important features\n",
    "using Logistic Regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9462219196732471\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('bool')\n",
    "X_train_std = X_train_std.astype('float')\n",
    "y_test = y_test.astype('bool')\n",
    "X_test_std = X_test_std.astype('float')\n",
    "lr = LogisticRegression(penalty='l1',\n",
    "                        C=1.0, \n",
    "                        solver = 'liblinear',\n",
    "                        multi_class='ovr')\n",
    "lr.fit(X_train_std,y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[lr.coef_!=0].shape # check the number of the features with non-zero weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X_train_std and X_test_std\n",
    "X_train_std = X_train_std[:, lr.coef_[0]!=0]\n",
    "X_test_std = X_test_std[:, lr.coef_[0]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22961689, -0.9697945 ,  0.08177691],\n",
       "       [-0.44197896, -0.34616214,  0.02136243],\n",
       "       [ 0.21700734,  0.57174562, -0.14996545],\n",
       "       ...,\n",
       "       [ 0.57657267, -0.7032342 ,  0.01563751],\n",
       "       [-1.33320484,  2.42935962, -0.4251332 ],\n",
       "       [ 0.43838658, -0.41878561, -0.03235142]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('bool')\n",
    "X_train_std = X_train_std.astype('float')\n",
    "pca = PCA(n_components = 3)\n",
    "lr = LogisticRegression (multi_class='ovr',\n",
    "                         solver='lbfgs')\n",
    "# dimensionality reduction:\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "# fitting the logistic regression model on the reduced dataset:\n",
    "X_train_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the selected features from above, we are going to apply LR / SVM / decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9473300262620368\n",
      "Test accuracy: 0.9465622872702518\n"
     ]
    }
   ],
   "source": [
    "# lr\n",
    "lr= LogisticRegression(penalty='l1',\n",
    "                       solver = 'liblinear',\n",
    "                       C=0.01)\n",
    "lr.fit(X_train_pca, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_pca, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9474759264662971\n",
      "Test accuracy: 0.9472430224642614\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVC(kernel='rbf', random_state=1, C=0.01, gamma=0.5) #gamma\n",
    "svm.fit(X_train_pca, y_train)\n",
    "\n",
    "print('Training accuracy:', svm.score(X_train_pca, y_train))\n",
    "print('Test accuracy:', svm.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.949518529325941\n",
      "Test accuracy: 0.9431586113002042\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier(criterion='gini',max_depth=5,random_state=1)\n",
    "tree.fit(X_train_pca, y_train)\n",
    "\n",
    "print('Training accuracy:', tree.score(X_train_pca, y_train))\n",
    "print('Test accuracy:', tree.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the methods using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.946\n"
     ]
    }
   ],
   "source": [
    "# pipeline_lr\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=3),\n",
    "                        LogisticRegression(random_state=1))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "#pipeline_SVM\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=3),\n",
    "                        SVC(random_state=1))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "#pipeline_Decision_Tree\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                        PCA(n_components=3),\n",
    "                        DecisionTreeClassifier(random_state=1))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Class dist.: [5195  288], Acc: 0.908\n",
      "Fold:  2, Class dist.: [5195  288], Acc: 0.915\n",
      "Fold:  3, Class dist.: [5195  288], Acc: 0.893\n",
      "Fold:  4, Class dist.: [5195  288], Acc: 0.899\n",
      "Fold:  5, Class dist.: [5196  288], Acc: 0.891\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5).split(X_train, y_train)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold): \n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test]) \n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "        np.bincount(y_train[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy: 0.901 +/- 0.009\n"
     ]
    }
   ],
   "source": [
    "print('\\nCV accuracy: %.3f +/- %.3f' % \n",
    "      (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0],\n",
    "              'logisticregression__penalty':['l1','l2']}\n",
    "grid = GridSearchCV(pipe_lr, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "gs=grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9474758996403567\n",
      "{'logisticregression__C': 0.0001, 'logisticregression__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test samples\n",
    "    if test_idx:\n",
    "        # plot all samples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=lr, test_idx=range(0, 50))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_01.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
